{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34b2064e",
   "metadata": {},
   "source": [
    "# Plotting Wildfire results for MOHITO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ece068",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b54307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as mticker\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.ticker import FuncFormatter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d82f80a",
   "metadata": {},
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb09176",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_eval_outputs = {\n",
    "    #key is the openness level\n",
    "    1: 'results/testOL1/testing_eval',\n",
    "    # 2: 'results/OL1_diff_ss_stoch/OL2_15_seed_testing',\n",
    "    # 3: 'results/OL1_diff_ss_stoch/OL3_15_seed_testing',\n",
    "    # #negative keys are for the ablation study\n",
    "    # -1: 'results/OL1_diff_ss_stoch_ablate/15_seed_testing',\n",
    "    # -2: 'results/OL2_diff_ss_stoch_ablate/15_seed_testing',\n",
    "    # -3: 'results/OL3_diff_ss_stoch_ablate/15_seed_testing',\n",
    "}\n",
    "\n",
    "policy_best_checkpoints = {\n",
    "    key: {} for key in policy_eval_outputs.keys()\n",
    "}\n",
    "\n",
    "#rename policies from logs to as appears in legend (in plotting order)\n",
    "policy_renaming = {\n",
    "    'mohito': 'MOHITO',\n",
    "    'mohito (Ablation)': 'MOHITO-NoTaskNodes',\n",
    "    'FifoBaseline': 'FCFS',\n",
    "    'WeakestBaseline': 'NTF',\n",
    "    'RandomBaseline': 'Random'\n",
    "}\n",
    "\n",
    "#this is a python 3.12 thing, dicts are actually ordered\n",
    "policy_order = list(policy_renaming.values())\n",
    "\n",
    "#path to the baseline root folder\n",
    "baseline_output_folder = 'baseline_test'\n",
    "\n",
    "#colors for plotting\n",
    "colors = ['#009ADE', 'red', '#AF58BA', '#FFC61E', '#F28522']\n",
    "\n",
    "use_these_starting_states = [\n",
    "    0, 1, 2\n",
    "]\n",
    "\n",
    "arrayify = lambda x: np.array(literal_eval(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344a3d76",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3809d73c",
   "metadata": {},
   "source": [
    "Select the best performing checkpoint.\n",
    "This can take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eb4b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "for openness_level, file_path in policy_eval_outputs.items():\n",
    "\n",
    "    dfs = [\n",
    "        (pd.read_csv(os.path.join(root, file)), root.split('/')[-1])\n",
    "        for root, _, files in os.walk(file_path)\n",
    "        for file in files if file.endswith('.csv') and 'logits' not in file\n",
    "    ]\n",
    "\n",
    "    print(openness_level)\n",
    "\n",
    "    dfs = pd.concat([df.assign(policy=file.split(';')[1].split('_')[0]) for df, file in dfs], ignore_index=True)\n",
    "\n",
    "    reward_cols = [col for col in dfs.columns if 'rewards' in col]\n",
    "\n",
    "    dfs['openness level'] = openness_level\n",
    "    dfs['starting state'] = dfs['description'].apply(lambda x: int(x.split('_')[2].split(';')[1]))\n",
    "    dfs['episodes'] = dfs['description'].apply(lambda x: int(x.split('_')[3].split(';')[1]))\n",
    "\n",
    "    original_dfs = dfs.copy()\n",
    "\n",
    "    dfs = dfs[['description', 'step', 'policy', 'openness level','starting state', 'episodes'] + reward_cols]\n",
    "    dfs.drop(columns=['description'], inplace=True)\n",
    "\n",
    "    #sum over steps\n",
    "    dfs = dfs.groupby(['policy', 'openness level', 'episodes', 'starting state']).sum().reset_index()\n",
    "    #mean over agent rewards\n",
    "    dfs['final_rewards'] = dfs[reward_cols].mean(axis=1)\n",
    "    #select specific starting states\n",
    "    dfs = dfs[dfs['starting state'].isin(use_these_starting_states)]\n",
    "    #mean over starting states\n",
    "    dfs = dfs.groupby(['policy', 'openness level', 'episodes']).mean()\n",
    "\n",
    "    #average over starting states / episodes generally speaking\n",
    "    pivot = pd.pivot_table(dfs, index=['openness level'], columns=['policy'], values='final_rewards', aggfunc='mean')\n",
    "\n",
    "    best_policy = pivot.idxmax(axis=1)\n",
    "    pivot = pivot[best_policy]\n",
    "\n",
    "\n",
    "    pivot_std = pd.pivot_table(dfs, index=['openness level'], columns=['policy'], values='final_rewards', aggfunc='std')\n",
    "    pivot_std = 1.96 * pivot_std / math.sqrt(45)\n",
    "    pivot_std = pivot_std[best_policy]\n",
    "\n",
    "    policy_best_checkpoints[openness_level]['mean'] = pivot\n",
    "    policy_best_checkpoints[openness_level]['ci'] = pivot_std\n",
    "    policy_best_checkpoints[openness_level]['checkpoint'] = best_policy\n",
    "    policy_best_checkpoints[openness_level]['dfs'] = original_dfs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5d90b0",
   "metadata": {},
   "source": [
    "Loading baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ca62ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.concat([\n",
    "    pd.read_csv(os.path.join(root, file))\n",
    "    for root, _, files in os.walk(baseline_output_folder) for file in files\n",
    "    if file.endswith('.csv')\n",
    "], ignore_index=True)\n",
    "\n",
    "reward_cols = [col for col in dfs.columns if 'rewards' in col]\n",
    "\n",
    "dfs = dfs[['description', 'step'] + reward_cols]\n",
    "dfs['policy'] = dfs['description'].apply(\n",
    "    lambda x: x.split('_')[0].split(';')[1])\n",
    "dfs['openness level'] = dfs['description'].apply(\n",
    "    lambda x: int(x.split('_')[1].split(';')[1]))\n",
    "dfs['starting state'] = dfs['description'].apply(\n",
    "    lambda x: int(x.split('_')[2].split(';')[1]))\n",
    "dfs['episodes'] = dfs['description'].apply(\n",
    "    lambda x: int(x.split('_')[3].split(';')[1]))\n",
    "dfs.drop(columns=['description'], inplace=True)\n",
    "\n",
    "#sum over steps\n",
    "dfs = dfs.groupby(['policy', 'openness level', 'episodes','starting state']).sum().reset_index()\n",
    "#mean over agent rewards\n",
    "dfs['final_rewards'] = dfs[reward_cols].mean(axis=1)\n",
    "#filter starting states \n",
    "dfs = dfs[dfs['starting state'].isin(use_these_starting_states)]\n",
    "# average over starting states\n",
    "dfs = dfs.groupby(['policy', 'openness level', 'episodes']).mean().reset_index()\n",
    "\n",
    "pivot = pd.pivot_table(dfs,\n",
    "                       index=['openness level'],\n",
    "                       columns=['policy'],\n",
    "                       values='final_rewards',\n",
    "                       aggfunc='mean')\n",
    "\n",
    "pivot_std = pd.pivot_table(dfs,\n",
    "                           index=['openness level'],\n",
    "                           columns=['policy'],\n",
    "                           values='final_rewards',\n",
    "                           aggfunc='std')\n",
    "pivot_std = 1.96 * pivot_std / math.sqrt(45)\n",
    "\n",
    "pivot.plot(\n",
    "    kind='bar',\n",
    "    yerr=pivot_std,\n",
    "    capsize=5,\n",
    "    figsize=(10, 6),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeaec3d",
   "metadata": {},
   "source": [
    "Concatenating baselines and MOHITO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886bdc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mohito_best_policy_df = pd.concat([\n",
    "    policy_best_checkpoints[openness_level]['mean']\n",
    "    for openness_level in policy_best_checkpoints\n",
    "])\n",
    "\n",
    "print(mohito_best_policy_df)\n",
    "\n",
    "#merge MOHITOX columns of nonNaNs into one column\n",
    "mohito_best_policy_df = mohito_best_policy_df.reset_index()\n",
    "mohito_best_policy_df = mohito_best_policy_df.melt(\n",
    "    id_vars=['openness level'],\n",
    "    var_name='policy',\n",
    "    value_name='final_rewards'\n",
    ").dropna()\n",
    "\n",
    "mohito_best_policy_df['policy'] = 'MOHITO'\n",
    "mohito_best_policy_df.set_index('openness level', inplace=True)\n",
    "\n",
    "#incorporate ablation results\n",
    "mohito_original_policy_df = mohito_best_policy_df[mohito_best_policy_df.index > 0]\n",
    "mohito_ablation_df = mohito_best_policy_df[mohito_best_policy_df.index < 0]\n",
    "\n",
    "#flip\n",
    "mohito_ablation_df.index = -mohito_ablation_df.index\n",
    "mohito_ablation_df['policy'] = mohito_ablation_df['policy'] + ' (Ablation)'\n",
    "mohito_best_policy_df = pd.concat([mohito_original_policy_df, mohito_ablation_df])\n",
    "\n",
    "\n",
    "print(mohito_best_policy_df)\n",
    "\n",
    "# Merge MOHITO and baseline dataframes\n",
    "pivot['mohito'] = mohito_best_policy_df['final_rewards'][mohito_best_policy_df['policy'] == 'MOHITO']\n",
    "pivot['mohito (Ablation)'] = mohito_best_policy_df['final_rewards'][mohito_best_policy_df['policy'] == 'MOHITO (Ablation)']\n",
    "print(pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025860c6",
   "metadata": {},
   "source": [
    "and ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfa3b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "mohito_best_std_df = pd.concat([\n",
    "    policy_best_checkpoints[openness_level]['ci']\n",
    "    for openness_level in policy_best_checkpoints\n",
    "])\n",
    "\n",
    "print(mohito_best_std_df)\n",
    "\n",
    "#merge MOHITOX columns of nonNaNs into one column\n",
    "mohito_best_std_df = mohito_best_std_df.reset_index()\n",
    "mohito_best_std_df = mohito_best_std_df.melt(\n",
    "    id_vars=['openness level'],\n",
    "    var_name='policy',\n",
    "    value_name='final_rewards'\n",
    ").dropna()\n",
    "\n",
    "mohito_best_std_df['policy'] = 'MOHITO'\n",
    "mohito_best_std_df.set_index('openness level', inplace=True)\n",
    "\n",
    "\n",
    "#incorporate ablation results\n",
    "mohito_original_std_df = mohito_best_std_df[mohito_best_std_df.index > 0]\n",
    "mohito_ablation_df = mohito_best_std_df[mohito_best_std_df.index < 0]\n",
    "\n",
    "#flip\n",
    "mohito_ablation_df.index = -mohito_ablation_df.index\n",
    "mohito_ablation_df['policy'] = mohito_ablation_df['policy'] + ' (Ablation)'\n",
    "mohito_best_std_df = pd.concat([mohito_original_std_df, mohito_ablation_df])\n",
    "\n",
    "\n",
    "\n",
    "print(mohito_best_std_df)\n",
    "\n",
    "# Merge MOHITO and baseline dataframes\n",
    "pivot_std['mohito'] = mohito_best_std_df['final_rewards'][mohito_best_std_df['policy'] == 'MOHITO']\n",
    "pivot_std['mohito (Ablation)'] = mohito_best_std_df['final_rewards'][mohito_best_std_df['policy'] == 'MOHITO (Ablation)']\n",
    "print(pivot_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1ce6b2",
   "metadata": {},
   "source": [
    "Preparing fire put/burn out times and counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4320f82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting a new dfs here\n",
    "dfs_puts = pd.concat([\n",
    "    pd.read_csv(os.path.join(root, file))\n",
    "    for root, _, files in os.walk(baseline_output_folder) for file in files\n",
    "    if file.endswith('.csv')\n",
    "], ignore_index=True)\n",
    "\n",
    "#get groups\n",
    "dfs_puts['policy'] = dfs_puts['description'].apply(\n",
    "    lambda x: x.split('_')[0].split(';')[1])\n",
    "dfs_puts['openness level'] = dfs_puts['description'].apply(\n",
    "    lambda x: int(x.split('_')[1].split(';')[1]))\n",
    "dfs_puts['starting state'] = dfs_puts['description'].apply(\n",
    "    lambda x: int(x.split('_')[2].split(';')[1]))\n",
    "dfs_puts['episodes'] = dfs_puts['description'].apply(\n",
    "    lambda x: int(x.split('_')[3].split(';')[1]))\n",
    "dfs_puts.drop(columns=['description'], inplace=True)\n",
    "\n",
    "#add MOHITO\n",
    "mohito_dict = {ol: (path, policy_best_checkpoints[ol]['checkpoint']) for ol, path in policy_eval_outputs.items()}\n",
    "mohito_dfs_puts = pd.concat([\n",
    "    policy_best_checkpoints[openness_level]['dfs'][policy_best_checkpoints[openness_level]['dfs']['policy'] == policy_best_checkpoints[openness_level]['checkpoint'].item()].copy()\n",
    "    for openness_level in mohito_dict\n",
    "])\n",
    "\n",
    "\n",
    "#handle the ablation\n",
    "mohito_ablation_dfs_puts = mohito_dfs_puts['openness level'] < 0\n",
    "mohito_dfs_puts['policy'] = 'mohito'\n",
    "mohito_ablation_policy_labels = mohito_dfs_puts[mohito_ablation_dfs_puts]['policy'].apply(lambda x: f'{x} (Ablation)')\n",
    "mohito_dfs_puts.loc[mohito_ablation_dfs_puts, 'policy'] = mohito_ablation_policy_labels\n",
    "mohito_dfs_puts['openness level'] = mohito_dfs_puts['openness level'].abs()\n",
    "\n",
    "#add MOHITO to the dfs\n",
    "dfs_puts = pd.concat([dfs_puts, mohito_dfs_puts], ignore_index=True)\n",
    "\n",
    "\n",
    "#get time column as np array\n",
    "dfs_puts = dfs_puts[['policy', 'step', 'openness level', 'episodes', 'starting state', 'infos/just_put_out_time',\n",
    "    'infos/just_put_out_ftype', 'infos/just_burned_out_time', 'infos/just_burned_out_ftype']]\n",
    "\n",
    "grouping = dfs_puts.groupby(['policy', 'openness level', 'starting state', 'episodes'])\n",
    "\n",
    "\n",
    "grouped_times = {p:[] for p in dfs_puts['policy'].unique()}\n",
    "\n",
    "\n",
    "# Iterate through policies and openness levels to get the times and types of put out and burned out fires\n",
    "for (name, group) in grouping:\n",
    "\n",
    "    group = group.reset_index()\n",
    "\n",
    "    try:\n",
    "        group['just_put_out_time'] = group['infos/just_put_out_time'].apply(arrayify)\n",
    "    except:\n",
    "        print('hh')\n",
    "\n",
    "    group['just_burned_out_time'] = group['infos/just_burned_out_time'].apply(arrayify)\n",
    "    group['just_put_out_ftype'] = group['infos/just_put_out_ftype'].apply(arrayify)\n",
    "    group['just_burned_out_ftype'] = group['infos/just_burned_out_ftype'].apply(arrayify)\n",
    "\n",
    "    #create stacked_cols\n",
    "    put_outs = pd.DataFrame({\n",
    "        'time': np.concatenate(group['just_put_out_time'].values),\n",
    "        'fire_type': np.concatenate(group['just_put_out_ftype'].values),\n",
    "        #repeat for the shape of each embeded array\n",
    "        'step': np.concatenate([[group['step'].values[i],] * group['just_put_out_time'].loc[i].shape[0] for i in range(len(group))]),\n",
    "    })\n",
    "    put_outs['burned_out'] = False\n",
    "\n",
    "    burn_outs = pd.DataFrame({\n",
    "        'time': np.concatenate(group['just_burned_out_time'].values),\n",
    "        'fire_type': np.concatenate(group['just_burned_out_ftype'].values),\n",
    "        'step': np.concatenate([[group['step'].values[i],] * group['just_burned_out_time'].loc[i].shape[0] for i in range(len(group))]),\n",
    "    })\n",
    "    burn_outs['burned_out'] = True\n",
    "\n",
    "    stacked_cols = pd.concat([put_outs, burn_outs], ignore_index=True)\n",
    "    stacked_cols['policy'] = name[0]\n",
    "    stacked_cols['openness_level'] = name[1]\n",
    "    stacked_cols['starting_state'] = name[2]\n",
    "    stacked_cols['episodes'] = name[3]\n",
    "    grouped_times[name[0]].append(stacked_cols)\n",
    "\n",
    "\n",
    "grouped_times = {\n",
    "    policy: pd.concat(times, ignore_index=True).reset_index()\n",
    "    for policy, times in grouped_times.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cc5615",
   "metadata": {},
   "source": [
    "## Analysis and Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef62b61a",
   "metadata": {},
   "source": [
    "### Rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502fb2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pivot.columns)\n",
    "\n",
    "pivot.rename(columns=policy_renaming, inplace=True)\n",
    "pivot_std.rename(columns=policy_renaming, inplace=True)\n",
    "\n",
    "#filter to just the renamed columns\n",
    "pivot = pivot[policy_order]\n",
    "pivot_std = pivot_std[policy_order]\n",
    "\n",
    "p1 = pivot.copy()\n",
    "p1_std = pivot_std.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ee4191",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1.plot(kind='bar',\n",
    "           yerr=p1_std,\n",
    "           capsize=5,\n",
    "           figsize=(7, 3),\n",
    "           title='Average Final Rewards by Openness Level and Policy',\n",
    "           color=colors,\n",
    "           width=0.8,)\n",
    "\n",
    "plt.title('')\n",
    "plt.yticks(size=12)\n",
    "plt.xticks(size=12, rotation=0)\n",
    "plt.ylim(-800, 1400)\n",
    "plt.xlabel('Openness Level', size=14)\n",
    "plt.ylabel('Mean Reward (with CI)', size=14)\n",
    "\n",
    "plt.legend(title=None, fontsize=12, labels=policy_order, ncol=5, prop={'size':10}, loc='lower center', bbox_to_anchor=(0.5, -0.41), columnspacing=1.5, handletextpad=0.5, handlelength=1.5, borderaxespad=0.5)\n",
    "\n",
    "\n",
    "print(p1)\n",
    "\n",
    "# plt.text(.73, -500, '-974', fontsize=12, backgroundcolor='white', color='black')\n",
    "# plt.text(1.18, -500, '-1030', fontsize=12, backgroundcolor='white', color='black')\n",
    "# plt.text(1.73, -500, '-988', fontsize=12, backgroundcolor='white', color='black')\n",
    "# plt.text(2.18, -500, '-1277', fontsize=12, backgroundcolor='white', color='black')\n",
    "\n",
    "plt.savefig('wildfire_rewards.pdf', bbox_inches='tight', dpi=300, transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587bc74f",
   "metadata": {},
   "source": [
    "### Wilcoxon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f656ec",
   "metadata": {},
   "source": [
    "over all openness levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f87753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add MOHITO\n",
    "mohito_dict = {ol: (path, policy_best_checkpoints[ol]['checkpoint']) for ol, path in policy_eval_outputs.items()}\n",
    "\n",
    "mohito_dfs = pd.concat([\n",
    "    policy_best_checkpoints[openness_level]['dfs'][policy_best_checkpoints[openness_level]['dfs']['policy'] == policy_best_checkpoints[openness_level]['checkpoint'].item()].copy()\n",
    "    for openness_level in mohito_dict\n",
    "])\n",
    "\n",
    "\n",
    "#handle the ablation\n",
    "mohito_ablation_dfs = mohito_dfs['openness level'] < 0\n",
    "mohito_dfs['policy'] = 'mohito'\n",
    "mohito_ablation_policy_labels = mohito_dfs[mohito_ablation_dfs]['policy'].apply(lambda x: f'{x} (Ablation)')\n",
    "mohito_dfs.loc[mohito_ablation_dfs, 'policy'] = mohito_ablation_policy_labels\n",
    "mohito_dfs['openness level'] = mohito_dfs['openness level'].abs()\n",
    "\n",
    "#add MOHITO to the dfs\n",
    "df_stats = pd.concat([dfs.copy(), mohito_dfs], ignore_index=True).copy()\n",
    "\n",
    "#sum over steps\n",
    "df_stats = df_stats.groupby(['policy', 'openness level', 'episodes','starting state'])[reward_cols].sum().reset_index()\n",
    "#mean over agent rewards\n",
    "df_stats['final_rewards'] = df_stats[reward_cols].mean(axis=1)\n",
    "#select starting states\n",
    "df_stats = df_stats[df_stats['starting state'].isin(use_these_starting_states)]\n",
    "#mean over starting states\n",
    "df_stats = df_stats.groupby(['policy', 'openness level', 'episodes']).mean().reset_index()\n",
    "\n",
    "#sort values (to ensure alignment for the Wilcoxon test)\n",
    "df_stats.sort_values(by=['policy','openness level','episodes'], inplace=True)\n",
    "\n",
    "dfg = df_stats.groupby(['policy'])\n",
    "\n",
    "for (policy, group) in dfg:\n",
    "\n",
    "    if policy == ('mohito', ):\n",
    "        continue\n",
    "\n",
    "    x = group.reset_index()\n",
    "    y = dfg.get_group(('mohito', )).reset_index()\n",
    "\n",
    "    #confirm correct indices\n",
    "    assert (x['openness level'] == y['openness level']).all(), \"Openness levels do not match between groups for Wilcoxon test.\"\n",
    "    assert (x['episodes'] == y['episodes']).all(), \"Episodes do not match between groups for Wilcoxon test.\"\n",
    "    assert (x['starting state'] == y['starting state']).all(), \"Starting states do not match between groups for Wilcoxon test.\"\n",
    "\n",
    "\n",
    "    print(f'Wilcoxon test: {policy} - MOHITO')\n",
    "    stat, p_value = stats.wilcoxon(\n",
    "        x['final_rewards'],\n",
    "        y['final_rewards'])\n",
    "    print(f'Statistic: {stat}, p-value: {p_value}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e26b75",
   "metadata": {},
   "source": [
    "over individual openness levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621856fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add MOHITO\n",
    "mohito_dict = {\n",
    "    ol: (path, policy_best_checkpoints[ol]['checkpoint'])\n",
    "    for ol, path in policy_eval_outputs.items()\n",
    "}\n",
    "\n",
    "mohito_dfs = pd.concat([\n",
    "    policy_best_checkpoints[openness_level]['dfs'][policy_best_checkpoints[openness_level]['dfs']['policy'] == policy_best_checkpoints[openness_level]['checkpoint'].item()].copy()\n",
    "    for openness_level in mohito_dict\n",
    "])\n",
    "\n",
    "\n",
    "#handle the ablation\n",
    "mohito_ablation_dfs = mohito_dfs['openness level'] < 0\n",
    "mohito_dfs['policy'] = 'mohito'\n",
    "mohito_ablation_policy_labels = mohito_dfs[mohito_ablation_dfs]['policy'].apply(lambda x: f'{x} (Ablation)')\n",
    "mohito_dfs.loc[mohito_ablation_dfs, 'policy'] = mohito_ablation_policy_labels\n",
    "mohito_dfs['openness level'] = mohito_dfs['openness level'].abs()\n",
    "\n",
    "# add MOHITO to the dfs\n",
    "df_stats = pd.concat([dfs.copy(), mohito_dfs], ignore_index=True).copy()\n",
    "\n",
    "# sum over steps\n",
    "df_stats = df_stats.groupby(['policy', 'openness level', 'episodes', 'starting state'])[reward_cols].sum().reset_index()\n",
    "# mean over agent rewards\n",
    "df_stats['final_rewards'] = df_stats[reward_cols].mean(axis=1)\n",
    "# select starting states\n",
    "df_stats = df_stats[df_stats['starting state'].isin(use_these_starting_states)]\n",
    "# mean over starting states\n",
    "df_stats = df_stats.groupby(['policy', 'openness level', 'episodes']).mean().reset_index()\n",
    "\n",
    "#sort values (to ensure alignment for the Wilcoxon test)\n",
    "df_stats.sort_values(by=['policy','openness level','episodes'], inplace=True)\n",
    "dfg = df_stats.groupby(['policy', 'openness level'])\n",
    "\n",
    "for (policy, group) in dfg:\n",
    "\n",
    "    if policy == ('mohito', policy[1]):\n",
    "        continue\n",
    "\n",
    "    print(f'Wilcoxon test: {policy} - MOHITO')\n",
    "    stat, p_value = stats.wilcoxon(\n",
    "        group['final_rewards'],\n",
    "        dfg.get_group(('mohito', policy[1]))['final_rewards'])\n",
    "    print(f'Statistic: {stat}, p-value: {p_value}')\n",
    "    print('---------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05a1d4a",
   "metadata": {},
   "source": [
    "### Task (wildfire) duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803ac89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = pd.concat(grouped_times.values(), ignore_index=True)\n",
    "\n",
    "gdf = gdf[gdf['policy'] != 'NoopBaseline'].copy()\n",
    "gdf = gdf[['time', 'openness_level', 'policy', 'starting_state','episodes']].groupby(['policy', 'openness_level', 'episodes', 'starting_state'])['time'].mean().reset_index()\n",
    "gdf = gdf.groupby(['policy', 'openness_level', 'episodes']).mean().reset_index()\n",
    "\n",
    "pivot = pd.pivot_table(gdf,\n",
    "    index = 'openness_level',\n",
    "    columns = 'policy',\n",
    "    values = 'time',\n",
    "    aggfunc='mean',\n",
    "    observed=True #don't consider the possibility of episodes with no fires. Shouldn't be possible...\n",
    ")\n",
    "\n",
    "pivot_std = pd.pivot_table(gdf,\n",
    "    index = 'openness_level',\n",
    "    columns = 'policy',\n",
    "    values = 'time',\n",
    "    aggfunc='std',\n",
    "    observed=True #don't consider the possibility of episodes with no fires. Shouldn't be possible...\n",
    ")\n",
    "pivot_std = 1.96 * pivot_std / math.sqrt(45)\n",
    "\n",
    "pivot.rename(columns=policy_renaming, inplace=True)\n",
    "pivot_std.rename(columns=policy_renaming, inplace=True)\n",
    "\n",
    "\n",
    "pivot = pivot.reindex(columns=policy_order, fill_value=0)\n",
    "pivot_std = pivot_std.reindex(columns=policy_order, fill_value=0)\n",
    "\n",
    "pivot.plot(kind='bar',\n",
    "           yerr=pivot_std,\n",
    "           capsize=5,\n",
    "           figsize=(7, 4),\n",
    "           width=.8,\n",
    "           title='Average Time to Put Out Fires by Openness Level and Policy',\n",
    "           color=colors)\n",
    "\n",
    "plt.title('')\n",
    "plt.legend(title=None, framealpha=0.0, fontsize=12, labels=policy_order, ncol=3, prop={'size':12}, loc='upper left')\n",
    "plt.yticks(size=14)\n",
    "plt.xticks(size=14, rotation=0)\n",
    "plt.ylim(0, 10)\n",
    "plt.ylabel(\"Fire Duration (in timesteps)\", size=14)\n",
    "plt.xlabel(\"Openness Level\",size=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig('wildfire_duration.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cc0d2b",
   "metadata": {},
   "source": [
    "### Wildfire put-out / burned-out fire counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404bd8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_counted_grouped_times = grouped_times.copy()\n",
    "\n",
    "fire_name = {\n",
    "    '1.0': 'Small',\n",
    "    '2.0': 'Medium',\n",
    "}\n",
    "\n",
    "#!Important: ensures that episodes without fires are counted as having 0 put-out or burned-out respectively.\n",
    "for policy in grouped_times:\n",
    "    for col in ['openness_level', 'policy', 'starting_state', 'episodes', 'fire_type', 'burned_out']:\n",
    "        pre_counted_grouped_times[policy][col] = pd.Categorical(pre_counted_grouped_times[policy][col].astype(str))\n",
    "    \n",
    "counted_grouped_times = pd.concat([\n",
    "    g.groupby(['policy','openness_level', 'burned_out', 'episodes', 'starting_state', 'fire_type'], observed=False)['time'].count().reset_index().groupby(\n",
    "        ['policy','openness_level', 'burned_out', 'episodes', 'fire_type'])['time'].mean().reset_index()\n",
    "    for policy, g in pre_counted_grouped_times.items()\n",
    "])\n",
    "\n",
    "for j, is_burned_out in enumerate(['True', 'False']):\n",
    "\n",
    "    these_grouped_times = counted_grouped_times[counted_grouped_times['burned_out'] == is_burned_out]\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 4), sharey=False)\n",
    "\n",
    "    for size in these_grouped_times['fire_type'].unique():\n",
    "\n",
    "\n",
    "        relabel = {'mohito': 'MOHITO', 'mohito (Ablation)': 'MOHITO-NoTaskNodes', 'FifoBaseline':'FCFS', 'WeakestBaseline': 'NTF', 'RandomBaseline': 'Random'}\n",
    "        order = ['MOHITO', 'MOHITO-NoTaskNodes', 'FCFS', 'NTF', 'Random']\n",
    "\n",
    "        ls_grouped_times = these_grouped_times[these_grouped_times['fire_type']  == size].copy()\n",
    "        ls_grouped_times['policy'] = ls_grouped_times['policy'].replace(relabel)\n",
    "        ls_grouped_times = ls_grouped_times[~ls_grouped_times['policy'].isin(['NoopBaseline',]) ]\n",
    "        \n",
    "        p = sns.boxplot(\n",
    "            x='openness_level',\n",
    "            y='time',\n",
    "            hue='policy',\n",
    "            data=ls_grouped_times,\n",
    "            ax=ax[int(float(size))-1],\n",
    "            width=0.8,\n",
    "            palette=colors,\n",
    "            hue_order = order,\n",
    "            showfliers=False,\n",
    "            medianprops={'color': 'black','linewidth':2},\n",
    "        )\n",
    "\n",
    "        #time here is actually the count of fires (counted off of the burn/put out time column shape groupe by ftype.)\n",
    "        group_means = ls_grouped_times.groupby(['openness_level', 'policy'], observed=False)['time'].mean().reset_index()\n",
    "\n",
    "        width = 0.8\n",
    "\n",
    "        dic_colors = {\n",
    "            k : (i - (len(order) -1) /2) * (width / len(order))\n",
    "            for i, k in enumerate(order)\n",
    "        }\n",
    "\n",
    "        offset_map = dic_colors\n",
    "        for i, row in group_means.iterrows():\n",
    "            x_pos = list(ls_grouped_times['openness_level'].unique()).index(row['openness_level']) + offset_map[row['policy']]\n",
    "            ax[int(float(size))-1].scatter(x_pos, row['time'], color='red', edgecolors='black',  marker='D', zorder=10)\n",
    "\n",
    "\n",
    "        ax[int(float(size))-1].yaxis.set_major_formatter(FuncFormatter(lambda y, _: f'{int(round(y))}'))\n",
    "\n",
    "        ax[int(float(size))-1].get_legend().remove()\n",
    "        ax[int(float(size))-1].set_xlabel(\"Openness Level\", size=14)\n",
    "        ax[int(float(size))-1].tick_params(axis='x', labelsize=14, rotation=0)\n",
    "        ax[int(float(size))-1].tick_params(axis='y', labelsize=14)\n",
    "        ax[int(float(size))-1].set_title(f\"{fire_name[size]} Fires\", size=16)\n",
    "\n",
    "        ax[int(float(size)-1)].set_ylabel(f\"{fire_name[size]} fires {'burned out' if is_burned_out == 'True' else 'put out'}\", size=16)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Externally constructing legend to avoid the mean markers being included in the legend\n",
    "    legend = []\n",
    "    if is_burned_out == 'True':\n",
    "        for i, l in enumerate(policy_order):\n",
    "            legend.append(\n",
    "                Line2D([0], [0], color=colors[i], lw=4, label=l)\n",
    "            )\n",
    "\n",
    "    \n",
    "    ax[0].legend(title=None, framealpha=1.0, fontsize=12, labels= policy_order, \n",
    "    ncol=5, loc='lower center', bbox_to_anchor=(1.08, -.32), handles=legend)\n",
    "\n",
    "plt.savefig(f'wildfire_fires_is_burned_out{is_burned_out == 'True'}.pdf', bbox_inches='tight', pad_inches=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5892856c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "three12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
